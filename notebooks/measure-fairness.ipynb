{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Measure fairness\n",
    "\n",
    "In this third notebook we're going to measure how fair our model is. We'll cover the following topics:\n",
    "\n",
    "* Loading a pretrained model\n",
    "* Loading the testing dataset\n",
    "* Using the FairlearnDashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from fairlearn.widget import FairlearnDashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pretrained model\n",
    "First, we're going to load the model that we trained in part 2.\n",
    "It's saved using `joblib`, so we'll use that to load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('../models/model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've loaded the model, we're loading up the test dataset for the model.\n",
    "This dataset contains samples that we haven't used during training. We can be sure that the model isn't going to remember these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the FairlearnDashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the model, and testing dataset, we can start looking at the fairness of the model.\n",
    "You would expect that male and female customers are equally likeky to get a credit card from our bank. So let's check if that's the case.\n",
    "\n",
    "The FairlearnDashboard needs a couple of things:\n",
    "\n",
    "* A set of sensitive features to test for\n",
    "* A set of names for the sensitive features\n",
    "* The ground truth for the model from the testing set.\n",
    "* The predictions made for the model based on the features in the testing set.\n",
    "\n",
    "When you create a new instance of the FairlearnDashboard you'll be asked to select a sensitive attribute and a metric.\n",
    "Once these are selected, you'll get a dashboard that displays two things:\n",
    "\n",
    "* The performance disparity: The difference in model performance between groups\n",
    "* The prediction disparity: The difference between groups in fraction resulting in a positive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.widget import FairlearnDashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_test['default.payment.next.month']\n",
    "predicted_outcomes = model.predict(df_test.drop(['SEX','default.payment.next.month'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89894c040c474c7d86800efd3f05d4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FairlearnWidget(value={'true_y': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<fairlearn.widget._fairlearn_dashboard.FairlearnDashboard at 0x7f357260ad50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FairlearnDashboard(\n",
    "    sensitive_features=df_test['SEX'],\n",
    "    sensitive_feature_names=['SEX'],\n",
    "    y_true=ground_truth,\n",
    "    y_pred=predicted_outcomes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bit3e11a6b61e3744178bd38bc2df8ae478"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
